{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMyEmb(original_emb):\n",
    "    \n",
    "    tmp = torch.FloatTensor(original_emb)\n",
    "    tmp = torch.mean(tmp, dim=0)\n",
    "    tmp = torch.nn.functional.normalize(tmp, p=2, dim=0)\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4494/4494)\n",
      "(2247/2247)\n"
     ]
    }
   ],
   "source": [
    "DA_LIST = 'data/testset_distribution_list.txt'\n",
    "DA_LIST2 = 'data/testset_test_list.txt'\n",
    "DA_PATH_ORIGINAL = '../vox_emb/test'\n",
    "# DA_PATH_PROCESSED = 'exp_emb/MyLinearNetv2_Exp4-2/emb_test'\n",
    "DA_PATH_PROCESSED = 'exp_emb/MyLinearNetv2_Exp5-3/emb_test'\n",
    "# DA_PATH_PROCESSED = 'exp_emb/MyLinearNetv2_Exp6-2/emb_test'\n",
    "\n",
    "# DA_LIST = 'data/trainset_distribution_list.txt'\n",
    "# DA_LIST2 = 'data/trainset_test_list.txt'\n",
    "# DA_PATH_ORIGINAL = '../vox_emb/train'\n",
    "# DA_PATH_PROCESSED = 'exp_emb/MyLinearNetv2_Exp4-2/emb_train'\n",
    "\n",
    "with open(DA_LIST) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open(DA_LIST2) as f2:\n",
    "    lines2 = f2.readlines()\n",
    "\n",
    "# # IF TRAIN SET -> USE SMALL AMOUNT\n",
    "# tmp_lines1 = lines[0:len(lines)//2]\n",
    "# tmp_lines2 = lines[len(lines)//2:]\n",
    "# tmp_lines1 = random.sample(tmp_lines1, len(tmp_lines1)//100)\n",
    "# tmp_lines2 = random.sample(tmp_lines2, len(tmp_lines2)//100)\n",
    "# lines = list()\n",
    "# lines.extend(tmp_lines1)\n",
    "# lines.extend(tmp_lines2)\n",
    "# tmp_lines1 = lines2[0:len(lines2)//2]\n",
    "# tmp_lines2 = lines2[len(lines2)//2:]\n",
    "# tmp_lines1 = random.sample(tmp_lines1, len(tmp_lines1)//100)\n",
    "# tmp_lines2 = random.sample(tmp_lines2, len(tmp_lines2)//100)\n",
    "# lines2 = list()\n",
    "# lines2.extend(tmp_lines1)\n",
    "# lines2.extend(tmp_lines2)\n",
    "\n",
    "\n",
    "same_cat_dist_original = []\n",
    "diff_cat_dist_original = []\n",
    "diff_spk_dist_original = []\n",
    "\n",
    "same_cat_dist_processed = []\n",
    "diff_cat_dist_processed = []\n",
    "diff_spk_dist_processed = []\n",
    "\n",
    "for idx, l in enumerate(lines):\n",
    "    tokens = l.strip().split()\n",
    "    flag = tokens[3]\n",
    "    file1 = tokens[1]\n",
    "    file2 = tokens[2]\n",
    "    \n",
    "    emb1 = np.load(os.path.join(DA_PATH_ORIGINAL, file1))\n",
    "    emb2 = np.load(os.path.join(DA_PATH_ORIGINAL, file2))\n",
    "    emb3 = np.load(os.path.join(DA_PATH_PROCESSED, file1))\n",
    "    emb4 = np.load(os.path.join(DA_PATH_PROCESSED, file2))    \n",
    "    emb1 = getMyEmb(emb1)\n",
    "    emb2 = getMyEmb(emb2)\n",
    "    emb3 = torch.FloatTensor(emb3)\n",
    "    emb4 = torch.FloatTensor(emb4)\n",
    "    \n",
    "    # print(torch.norm(emb1), torch.norm(emb2), torch.norm(emb3), torch.norm(emb4))\n",
    "    \n",
    "    # # L2 distance\n",
    "    # dist_original = torch.dist(emb1, emb2).item()\n",
    "    # dist_processed = torch.dist(emb3, emb4).item()\n",
    "    \n",
    "    # cosine simliarity\n",
    "    dist_original = 1 - torch.nn.functional.cosine_similarity(emb1, emb2, dim=0).item()\n",
    "    dist_processed = 1 - torch.nn.functional.cosine_similarity(emb3, emb4, dim=0).item()\n",
    "    \n",
    "    if flag == '1':\n",
    "        same_cat_dist_original.append(dist_original)\n",
    "        same_cat_dist_processed.append(dist_processed)\n",
    "    else:\n",
    "        diff_cat_dist_original.append(dist_original)\n",
    "        diff_cat_dist_processed.append(dist_processed)\n",
    "    \n",
    "    print('\\r({}/{})'.format(idx+1, len(lines)), end='')\n",
    "\n",
    "print()\n",
    "\n",
    "lines2 = lines2[1::2]\n",
    "lines2 = random.sample(lines2, len(lines)//2)\n",
    "\n",
    "for idx, l in enumerate(lines2):\n",
    "    tokens = l.strip().split()\n",
    "    flag = tokens[0]\n",
    "    file1 = tokens[1]\n",
    "    file2 = tokens[2]\n",
    "    \n",
    "    if flag == '1':\n",
    "        continue\n",
    "    \n",
    "    emb1 = np.load(os.path.join(DA_PATH_ORIGINAL, file1))\n",
    "    emb2 = np.load(os.path.join(DA_PATH_ORIGINAL, file2))\n",
    "    emb3 = np.load(os.path.join(DA_PATH_PROCESSED, file1))\n",
    "    emb4 = np.load(os.path.join(DA_PATH_PROCESSED, file2))    \n",
    "    emb1 = getMyEmb(emb1)\n",
    "    emb2 = getMyEmb(emb2)\n",
    "    emb3 = torch.FloatTensor(emb3)\n",
    "    emb4 = torch.FloatTensor(emb4)\n",
    "    # print(torch.norm(emb1), torch.norm(emb2), torch.norm(emb3), torch.norm(emb4))\n",
    "    \n",
    "    # # L2 distance\n",
    "    # dist_original = torch.dist(emb1, emb2).item()\n",
    "    # dist_processed = torch.dist(emb3, emb4).item()\n",
    "    \n",
    "    # cosine simliarity\n",
    "    dist_original = 1 - torch.nn.functional.cosine_similarity(emb1, emb2, dim=0).item()\n",
    "    dist_processed = 1 - torch.nn.functional.cosine_similarity(emb3, emb4, dim=0).item()\n",
    "    \n",
    "    diff_spk_dist_original.append(dist_original)\n",
    "    diff_spk_dist_processed.append(dist_processed)\n",
    "    \n",
    "    print('\\r({}/{})'.format(idx+1, len(lines2)), end='')\n",
    "\n",
    "# diff_spk_dist_original = random.sample(diff_spk_dist_original, len(diff_cat_dist_original))\n",
    "# diff_spk_dist_processed = random.sample(diff_spk_dist_processed, len(diff_cat_dist_processed))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(same_cat_dist_original, bins=60, histtype='stepfilled', color='blue', alpha=0.5)\n",
    "# plt.hist(diff_cat_dist_original, bins=60, histtype='stepfilled', color='blue', alpha=0.5)\n",
    "# plt.hist(diff_spk_dist_original, bins=60, histtype='stepfilled', color='blue', alpha=0.5)\n",
    "\n",
    "# plt.hist(same_cat_dist_processed, bins=60, histtype='stepfilled', color='red', alpha=0.5)\n",
    "# plt.hist(diff_cat_dist_processed, bins=60, histtype='stepfilled', color='red', alpha=0.5)\n",
    "# plt.hist(diff_spk_dist_processed, bins=60, histtype='stepfilled', color='red', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.hist(same_cat_dist_original, bins=60, histtype='step', color='blue')\n",
    "plt.hist(diff_cat_dist_original, bins=60, histtype='step', color='blue')\n",
    "plt.hist(diff_spk_dist_original, bins=60, histtype='step', color='red')\n",
    "\n",
    "# plt.hist(same_cat_dist_processed, bins=60, histtype='step', color='red')\n",
    "# plt.hist(diff_cat_dist_processed, bins=60, histtype='step', color='red')\n",
    "# plt.hist(diff_spk_dist_processed, bins=60, histtype='step', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_LIST = 'data/testset_distribution_list.txt'\n",
    "DA_LIST2 = 'data/testset_test_list.txt'\n",
    "DA_PATH_P1 = 'exp_emb/MyLinearNetv2_Exp5-3/emb_test'\n",
    "DA_PATH_P2 = 'exp_emb/MyLinearNetv2_Exp6-1/emb_test'\n",
    "\n",
    "# DA_LIST = 'data/trainset_distribution_list.txt'\n",
    "# DA_PATH_P1 = '../vox_emb/train'\n",
    "# DA_PATH_P2 = 'exp_emb/MyLinearNetv2_Exp6-2/emb_train'\n",
    "\n",
    "with open(DA_LIST) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "with open(DA_LIST2) as f2:\n",
    "    lines2 = f2.readlines()\n",
    "\n",
    "# # IF TRAIN SET -> USE SMALL AMOUNT\n",
    "# lines1 = lines[0:len(lines)//2]\n",
    "# lines2 = lines[len(lines)//2:]\n",
    "# tmp_lines1 = random.sample(lines1, len(lines1)//100)\n",
    "# tmp_lines2 = random.sample(lines2, len(lines2)//100)\n",
    "# lines = list()\n",
    "# lines.extend(tmp_lines1)\n",
    "# lines.extend(tmp_lines2)\n",
    "\n",
    "\n",
    "same_cat_dist_P1 = []\n",
    "diff_cat_dist_P1 = []\n",
    "diff_spk_dist_P1 = []\n",
    "\n",
    "same_cat_dist_P2 = []\n",
    "diff_cat_dist_P2 = []\n",
    "diff_spk_dist_P2 = []\n",
    "\n",
    "for idx, l in enumerate(lines):\n",
    "    tokens = l.strip().split()\n",
    "    flag = tokens[3]\n",
    "    file1 = tokens[1]\n",
    "    file2 = tokens[2]\n",
    "    \n",
    "    emb1 = np.load(os.path.join(DA_PATH_P1, file1))\n",
    "    emb2 = np.load(os.path.join(DA_PATH_P1, file2))\n",
    "    emb3 = np.load(os.path.join(DA_PATH_P2, file1))\n",
    "    emb4 = np.load(os.path.join(DA_PATH_P2, file2))    \n",
    "    emb1 = getMyEmb(emb1)\n",
    "    emb2 = getMyEmb(emb2)\n",
    "    emb3 = torch.FloatTensor(emb3)\n",
    "    emb4 = torch.FloatTensor(emb4)\n",
    "    \n",
    "    # # L2 distance\n",
    "    # dist_P1 = torch.dist(emb1, emb2).item()\n",
    "    # dist_P2 = torch.dist(emb3, emb4).item()\n",
    "    \n",
    "    # cosine simliarity\n",
    "    dist_P1 = 1 - torch.nn.functional.cosine_similarity(emb1, emb2, dim=0).item()\n",
    "    dist_P2 = 1 - torch.nn.functional.cosine_similarity(emb3, emb4, dim=0).item()\n",
    "    \n",
    "    if flag == '1':\n",
    "        same_cat_dist_P1.append(dist_P1)\n",
    "        same_cat_dist_P2.append(dist_P2)\n",
    "    else:\n",
    "        diff_cat_dist_P1.append(dist_P1)\n",
    "        diff_cat_dist_P2.append(dist_P2)\n",
    "    \n",
    "    print('\\r({}/{})'.format(idx+1, len(lines)), end='')\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "for idx, l in enumerate(lines2):\n",
    "    tokens = l.strip().split()\n",
    "    flag = tokens[0]\n",
    "    file1 = tokens[1]\n",
    "    file2 = tokens[2]\n",
    "    \n",
    "    if flag == '1':\n",
    "        continue\n",
    "    \n",
    "    emb1 = np.load(os.path.join(DA_PATH_P1, file1))\n",
    "    emb2 = np.load(os.path.join(DA_PATH_P1, file2))\n",
    "    emb3 = np.load(os.path.join(DA_PATH_P2, file1))\n",
    "    emb4 = np.load(os.path.join(DA_PATH_P2, file2))    \n",
    "    emb1 = getMyEmb(emb1)\n",
    "    emb2 = getMyEmb(emb2)\n",
    "    emb3 = torch.FloatTensor(emb3)\n",
    "    emb4 = torch.FloatTensor(emb4)\n",
    "    \n",
    "    # # L2 distance\n",
    "    # dist_P1 = torch.dist(emb1, emb2).item()\n",
    "    # dist_P2 = torch.dist(emb3, emb4).item()\n",
    "    \n",
    "    # cosine simliarity\n",
    "    dist_P1 = 1 - torch.nn.functional.cosine_similarity(emb1, emb2, dim=0).item()\n",
    "    dist_P2 = 1 - torch.nn.functional.cosine_similarity(emb3, emb4, dim=0).item()\n",
    "    \n",
    "    diff_spk_dist_P1.append(dist_P1)\n",
    "    diff_spk_dist_P2.append(dist_P2)\n",
    "    \n",
    "    print('\\r({}/{})'.format(idx+1, len(lines2)), end='')\n",
    "\n",
    "diff_spk_dist_P1 = random.sample(diff_spk_dist_P1, len(diff_cat_dist_P1))\n",
    "diff_spk_dist_P2 = random.sample(diff_spk_dist_P2, len(diff_cat_dist_P2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(same_cat_dist_P1, bins=60, histtype='stepfilled', color='blue', alpha=0.5)\n",
    "# plt.hist(diff_cat_dist_P1, bins=60, histtype='stepfilled', color='blue', alpha=0.5)\n",
    "# plt.hist(diff_spk_dist_P1, bins=60, histtype='stepfilled', color='blue', alpha=0.5)\n",
    "\n",
    "# plt.hist(same_cat_dist_P2, bins=60, histtype='stepfilled', color='red', alpha=0.5)\n",
    "# plt.hist(diff_cat_dist_P2, bins=60, histtype='stepfilled', color='red', alpha=0.5)\n",
    "# plt.hist(diff_spk_dist_P2, bins=60, histtype='stepfilled', color='red', alpha=0.5)\n",
    "\n",
    "\n",
    "# plt.hist(same_cat_dist_P1, bins=60, histtype='step', color='blue')\n",
    "# plt.hist(diff_cat_dist_P1, bins=60, histtype='step', color='blue')\n",
    "# plt.hist(diff_spk_dist_P1, bins=60, histtype='step', color='blue')\n",
    "\n",
    "plt.hist(same_cat_dist_P2, bins=60, histtype='step', color='red')\n",
    "plt.hist(diff_cat_dist_P2, bins=60, histtype='step', color='red')\n",
    "plt.hist(diff_spk_dist_P2, bins=60, histtype='step', color='red')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_PATH = '../vox_emb/test'\n",
    "emb_list = []\n",
    "for item in os.listdir(EMB_PATH):\n",
    "    if item.endswith('type2.npy'):\n",
    "        emb = np.load(os.path.join(EMB_PATH, item))\n",
    "        emb = torch.FloatTensor(emb)\n",
    "        emb_list.append(emb)\n",
    "\n",
    "dist_list = []\n",
    "for idx, i in enumerate(emb_list):\n",
    "    for idx2, j in enumerate(emb_list):\n",
    "        if idx <= idx2: continue\n",
    "        dist = 1 - torch.nn.functional.cosine_similarity(i, j, dim=0).item()\n",
    "        dist_list.append(dist)\n",
    "    \n",
    "print(len(dist_list))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dist_list, bins=60, histtype='step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37c2112bdabb60b81a1d7aa8b65e7845a85b887fb3f0d445753830fa6b6ef431"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
